# ML 三轮迭代测试结论（GPU 改进计划）

基于 3 轮迭代实测结果的记录与行动建议，供后续训练与选型参考。

---

## 1. 三轮结果汇总

| 轮次 | 改进内容           | AUC 变化   | 状态     |
|------|--------------------|------------|----------|
| 第1轮 | 高频微结构特征 (7个) | **+3.52%** | ✅ 建议采用 |
| 第2轮 | Stacking Ensemble  | **-13.35%** | ❌ 不建议 |
| 第3轮 | 高级特征工程       | **-4.45%** | ❌ 不建议 |

- **基线**：LightGBM 单模型 AUC ≈ 0.5691  
- **第2轮**：Stacking 在约 4241 样本下 AUC 0.4931，相对基线 -13.35%，元学习器严重过拟合  
- **结论**：小数据集上 Stacking 反而降低性能；优先采用第1轮微结构特征，暂不训练 Stacking

---

## 2. 重要结论：Stacking

- **现象**：数据量约 4241 时，Stacking 表现远差于单模型 LightGBM。  
- **原因**：样本不足导致元学习器过拟合。  
- **建议**：  
  - ❌ **暂不训练 Stacking 模型**（避免浪费 H800 且效果更差）  
  - ✅ 实盘/回测继续使用 **加权 LGB + LSTM + TFT + 跨资产 LGB**（无 stacking_meta 时已默认此路径）  
  - ✅ **等数据量扩大到 20000+ 样本后再重试 Stacking**，并做 OOS 对比  

当前代码逻辑：若存在 `stacking_meta.json` + `stacking_meta.pkl` 则用 Stacking，否则用加权融合；**不部署新训练的 Stacking 到生产即可**，无需改推理代码。

---

## 3. 建议的下一步

**立即执行：**

1. **采用高频微结构特征**（已在 `ml_features.py` 中实现）  
   - 含 cum_ofi、ofi_std5、buy_sell_pressure 等 7 个特征，预期 AUC 提升约 3.5%。  
2. **扩大数据集**  
   - 从约 180 天扩展到 1–2 年，目标有效样本 10000+，为后续复杂模型打基础。

**暂缓执行：**

- ❌ Stacking 训练（小数据下效果差）  
- ❌ CatBoost / 其他复杂集成（待数据量充足后再评估）

---

## 4. 参考文件（若存在）

- 详细测试结果：`test_iteration2_result.json`、`GPU_IMPROVEMENT_SUMMARY.md`  
- 迭代脚本：`test_iteration*.py`

（以上文件若在本地或它分支，可一并纳入版本管理以便复现。）
